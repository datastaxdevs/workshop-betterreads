2023-02-20 14:39:53 INFO  Username and password provided but auth provider not specified, inferring PlainTextAuthProvider
2023-02-20 14:39:53 INFO  A cloud secure connect bundle was provided: ignoring all explicit contact points.
2023-02-20 14:39:53 INFO  A cloud secure connect bundle was provided and selected operation performs writes: changing default consistency level to LOCAL_QUORUM.
2023-02-20 14:39:53 INFO  Operation directory: /Users/cedricklunven/dev/workspaces/datastax-workshops/workshop-betterreads/logs/LOAD_20230220-143953-223698
2023-02-20 14:39:58 INFO  Setting executor.maxPerSecond not set when connecting to DataStax Astra: applying a limit of 9,000 ops/second based on the number of coordinators (3).
2023-02-20 14:39:58 INFO  If your Astra database has higher limits, please define executor.maxPerSecond explicitly.
2023-02-20 14:40:12 WARN  At least 1 record does not match the provided schema.mapping or schema.query. Please check that the connector configuration and the schema configuration are correct.
2023-02-20 14:40:17 WARN  Query generated server-side warning: Detected collection author_id with 21 items, greater than the maximum recommended (20)
2023-02-20 14:40:30 WARN  Query generated server-side warning: Detected collection author_id with 32 items, greater than the maximum recommended (20)
2023-02-20 14:41:25 WARN  Query generated server-side warning: Detected collection author_id with 29 items, greater than the maximum recommended (20)
2023-02-20 14:41:31 ERROR Operation LOAD_20230220-143953-223698 aborted: Too many errors, the maximum allowed is 100.
com.datastax.oss.dsbulk.workflow.api.error.TooManyErrorsException: Too many errors, the maximum allowed is 100.
	at com.datastax.oss.dsbulk.workflow.commons.log.LogManager.maybeTriggerOnError(LogManager.java:1031)
	at com.datastax.oss.dsbulk.workflow.commons.log.LogManager.lambda$newUnmappableStatementsHandler$6(LogManager.java:314)
	at java.base/java.lang.Thread.run(Thread.java:833) [21 skipped]
	Suppressed: java.lang.Exception: #block terminated with an error
		at com.datastax.oss.dsbulk.workflow.load.LoadWorkflow.execute(LoadWorkflow.java:242) [2 skipped]
		at com.datastax.oss.dsbulk.runner.WorkflowThread.run(WorkflowThread.java:53)
2023-02-20 14:41:33 INFO  Final stats:
2023-02-20 14:41:33 INFO  Rejected records can be found in the following file(s): mapping.bad, connector.bad
2023-02-20 14:41:33 INFO  Errors are detailed in the following file(s): connector-errors.log, mapping-errors.log
2023-02-20 14:41:33 INFO  Checkpoints for the current operation were written to checkpoint.csv.
2023-02-20 14:41:33 INFO  To resume the current operation, re-run it with the same settings, and add the following command line flag:
2023-02-20 14:41:33 INFO  --dsbulk.log.checkpoint.file=/Users/cedricklunven/dev/workspaces/datastax-workshops/workshop-betterreads/logs/LOAD_20230220-143953-223698/checkpoint.csv
